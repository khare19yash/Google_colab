{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/khare19yash/Google_colab/blob/master/Untitled2.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "cLO8aSIU2ExA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6cEzCXl02N1q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Authenticate and create PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "njo3Q5PJ2tUn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "e77d33ec-d75e-40c1-bfd0-1eb559c81d18"
      },
      "cell_type": "code",
      "source": [
        "# choose a local (colab) directory to store the data.\n",
        "local_download_path = os.path.expanduser('~/data')\n",
        "try:\n",
        "  os.makedirs(local_download_path)\n",
        "except: pass\n",
        "\n",
        "# 2. Auto-iterate using the query syntax\n",
        "#    https://developers.google.com/drive/v2/web/search-parameters\n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'1jbeyGqPmjfVBMvgZ4cW4X92ykLutDJFM' in parents\"}).GetList()\n",
        "\n",
        "for f in file_list:\n",
        "  # 3. Create & download by id.\n",
        "  print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "  fname = os.path.join(local_download_path, f['title'])\n",
        "  print('downloading to {}'.format(fname))\n",
        "  f_ = drive.CreateFile({'id': f['id']})\n",
        "  f_.GetContentFile(fname)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: data_test.csv, id: 1tYEfju0YCYWAHguShJckG5ZpU_Ojg0f4\n",
            "downloading to /root/data/data_test.csv\n",
            "title: data_train.csv, id: 1odT96GUX7x_Dfvn-sFJdMLewnpPTLp6O\n",
            "downloading to /root/data/data_train.csv\n",
            "title: readme, id: 1VcpZb1V7ZnROtAbfXoFSLLsBpRcbansd\n",
            "downloading to /root/data/readme\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CKidp3Kr3VY5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "2ac6c40d-9288-447f-b166-edc4aee99e7a"
      },
      "cell_type": "code",
      "source": [
        "#read training data \n",
        "PATH = '/root/data/data_train.csv'\n",
        "\n",
        "raw_train_data = pd.read_csv(PATH)\n",
        "print(raw_train_data.head())\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   id  num1  num2  num3  num4  num5  num6  num7  num8  num9   ...    cat6  \\\n",
            "0   0     2     5     0     1     0     0     0     0     0   ...     NaN   \n",
            "1   1     1     7     0     0     1     0     0     0     0   ...     NaN   \n",
            "2   2     5     9     0     0     1     0     0     0     0   ...     NaN   \n",
            "3   3     0     2     1     0     0     0     0     0     0   ...     0.0   \n",
            "4   4     0     0     1     0     0     0     0     0     0   ...     NaN   \n",
            "\n",
            "   cat7  cat8  cat9  cat10  cat11  cat12  cat13  cat14  target  \n",
            "0     0   1.0     4    1.0      0    0.0      1     12       0  \n",
            "1     0   NaN    11    1.0      1    2.0      1     19       0  \n",
            "2     0   NaN    14    1.0      1    2.0      1     60       0  \n",
            "3     0   1.0    11    1.0      1    3.0      1    104       0  \n",
            "4     0   NaN    14    1.0      1    2.0      1     82       0  \n",
            "\n",
            "[5 rows x 58 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xkV6AYPjlJT_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb01e00c-fc44-4e44-c959-289c41cdfb59"
      },
      "cell_type": "code",
      "source": [
        "#read test data\n",
        "PATH = '/root/data/data_test.csv'\n",
        "\n",
        "raw_test_data = pd.read_csv(PATH)\n",
        "print(raw_test_data.shape)\n",
        "#store test data id\n",
        "test_id = raw_test_data['id'].values"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(892816, 57)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tb310u8l9Z5m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1042
        },
        "outputId": "896290ab-8ef7-473f-8d2d-e0a49c86355e"
      },
      "cell_type": "code",
      "source": [
        "#counting total na values in each column\n",
        "total_na = raw_train_data.isna().sum()\n",
        "print(total_na)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id             0\n",
            "num1           0\n",
            "num2           0\n",
            "num3           0\n",
            "num4           0\n",
            "num5           0\n",
            "num6           0\n",
            "num7           0\n",
            "num8           0\n",
            "num9           0\n",
            "num10          0\n",
            "num11          0\n",
            "num12          0\n",
            "num13          0\n",
            "num14          0\n",
            "num15          0\n",
            "num16          0\n",
            "num17          0\n",
            "num18     107909\n",
            "num19          5\n",
            "num20          1\n",
            "num21          0\n",
            "num22      42667\n",
            "num23          0\n",
            "der1           0\n",
            "der2           0\n",
            "der3           0\n",
            "der4           0\n",
            "der5           0\n",
            "der6           0\n",
            "der7           0\n",
            "der8           0\n",
            "der9           0\n",
            "der10          0\n",
            "der11          0\n",
            "der12          0\n",
            "der13          0\n",
            "der14          0\n",
            "der15          0\n",
            "der16          0\n",
            "der17          0\n",
            "der18          0\n",
            "der19          0\n",
            "cat1         217\n",
            "cat2          83\n",
            "cat3        5814\n",
            "cat4         107\n",
            "cat5           5\n",
            "cat6      411792\n",
            "cat7           0\n",
            "cat8      266928\n",
            "cat9           0\n",
            "cat10      11503\n",
            "cat11          0\n",
            "cat12        570\n",
            "cat13          0\n",
            "cat14          0\n",
            "target         0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JMDL8zUsSr48",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing**\n",
        "\n",
        "\n",
        "\n",
        "1.   Replace missing values in numerical variables by mean\n",
        "2.   Replace missing values in categorical variables by creating new category.\n",
        "\n",
        "1.  Convert all numerical values between 0 and  1\n",
        "\n",
        "1.   Convert all categorical values into label encoding and one hot encoding\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "OkKnIiXpRM8B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def one_hot_encoding(data,column_names):\n",
        "  \n",
        "  data = pd.get_dummies(data , columns = column_names , prefix = column_names)\n",
        "  return data  \n",
        "\n",
        "\n",
        "def normalize_values(data,column_names):\n",
        "  num_min = data[column_names].min()\n",
        "  num_max = data[column_names].max()\n",
        "  \n",
        "  norm_val = num_max - num_min\n",
        "  data[column_names] = (data[column_names] - num_min) / norm_val\n",
        "  \n",
        "  return data\n",
        "\n",
        "\n",
        "def preprocess_data(data):\n",
        "  \n",
        "  column_names = list(data.columns.values)\n",
        "  num_columns = column_names[1:24]\n",
        "  der_numerical_columns = column_names[24:27]\n",
        "  der_categorical_columns = column_names[27:43]\n",
        "  cat_columns = column_names[43:]\n",
        "  \n",
        "  #handling missing values in numerical variables \n",
        "  data[num_columns] = data[num_columns].fillna(data[num_columns].mean())\n",
        "  \n",
        "  \n",
        "  #drop some columns \n",
        "  drop_columns = ['cat6','cat8']\n",
        "  \n",
        "  cat_columns.remove('cat6')\n",
        "  cat_columns.remove('cat8')\n",
        "  \n",
        "  data = data.drop(columns = drop_columns)\n",
        "  \n",
        "  #handling missing values in categorical variables \n",
        "  data[cat_columns] = data[cat_columns].fillna(\"NA\")\n",
        "  \n",
        "  #label encoding \n",
        "  cat_datatype_columns = data.select_dtypes(['object']).columns\n",
        "  \n",
        "  for column in cat_datatype_columns:\n",
        "    data[column] = data[column].astype('category')\n",
        "    \n",
        "  data[cat_datatype_columns] = data[cat_datatype_columns].apply(lambda x:x.cat.codes)\n",
        "  \n",
        "  #one hot encoding\n",
        "  data = one_hot_encoding(data,der_categorical_columns)\n",
        "  data = one_hot_encoding(data,cat_columns)\n",
        "  \n",
        "  \n",
        "  #normalize numerical values\n",
        "  data = normalize_values(data,num_columns)\n",
        "  data = normalize_values(data,der_numerical_columns)\n",
        "  \n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ui38akUtbX-i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "135ccfb4-cd53-4964-afb1-dd20e3a4ec0b"
      },
      "cell_type": "code",
      "source": [
        "#seperate out the target values from the training data\n",
        "target = raw_train_data['target'].values\n",
        "raw_data = raw_train_data.drop(columns = ['target'])\n",
        "print(raw_train_data.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(596000, 58)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eKdWeUz2_jQX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c4444c57-3408-4e89-b012-9f1bf5825eb9"
      },
      "cell_type": "code",
      "source": [
        "#preprocess raw training data\n",
        "prep_train_data = preprocess_data(raw_data)\n",
        "print(prep_train_data.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(596000, 363)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uTyrAdFnc0rV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96209b86-ef91-45c4-faa6-c6c59eb998cd"
      },
      "cell_type": "code",
      "source": [
        "#preprocess raw test data\n",
        "prep_test_data = preprocess_data(raw_test_data)\n",
        "print(prep_test_data.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(892816, 367)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xb1eBA2yq-My",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d3d43ac-c2ac-4f20-b066-a52b18e11ddc"
      },
      "cell_type": "code",
      "source": [
        "train_columns = prep_train_data.columns.values\n",
        "test_columns = prep_test_data\n",
        "\n",
        "s = set(test_columns) - set(train_columns)\n",
        "print(s)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'der11_20', 'der8_1', 'der14_28', 'der13_14', 'der12_11', 'der13_15'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "51eb3-O3T5Hg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Define training and validation size\n",
        "\n",
        "n_training = 500000\n",
        "n_validation = 96000\n",
        "n_test = 892816\n",
        "\n",
        "\n",
        "    \n",
        "#Divide data into training set and validation set\n",
        "\n",
        "# removing id column\n",
        "def get_train_test_data(prep_train_data,target,prep_test_data):\n",
        "  prep_train_data = prep_train_data.drop(columns = ['id'])\n",
        "  prep_test_data = prep_test_data.drop(columns = ['id'])\n",
        "  y_train = target\n",
        "  x_train = prep_train_data.values\n",
        "  N,M = x_train.shape\n",
        "  indices = np.arange(N)\n",
        "  np.random.shuffle(indices)\n",
        "  x_train = x_train[indices]\n",
        "  y_train = y_train[indices]\n",
        "\n",
        "\n",
        "  x_val = x_train[:n_validation]\n",
        "  y_val = y_train[:n_validation]\n",
        "  val_set = (x_val,y_val)\n",
        "\n",
        "\n",
        "  x_train = x_train[n_validation:n_validation+n_training]\n",
        "  y_train = y_train[n_validation:n_validation+n_training]\n",
        "  train_set = (x_train,y_train)\n",
        "  \n",
        "  print(x_train.shape)\n",
        "  print(y_train.shape)\n",
        "  print(x_val.shape)\n",
        "  print(y_val.shape)\n",
        "  test = prep_test_data.values\n",
        "  return train_set,val_set,test\n",
        "  \n",
        "\n",
        "class Model():\n",
        "  def __init__(self):\n",
        "    self.lrate = 0.0001\n",
        "    self.batch_size = 128 \n",
        "    self.ntrain = 500000\n",
        "    self.nclasses = 2\n",
        "    self.ntest = 892816 \n",
        "    \n",
        "  def get_data(self,prep_train_data,target,prep_test_data):\n",
        "    with tf.name_scope('data'):\n",
        "      # Create dataset and iterator\n",
        "      train,val,test = get_train_test_data(prep_train_data,target,prep_test_data)\n",
        "      train_data = tf.data.Dataset.from_tensor_slices(train)\n",
        "      train_data = train_data.shuffle(100000)\n",
        "      train_data = train_data.batch(self.batch_size)\n",
        "\n",
        "      val_data = tf.data.Dataset.from_tensor_slices(val)\n",
        "      val_data = val_data.batch(self.batch_size)\n",
        "\n",
        "\n",
        "      test_data = tf.data.Dataset.from_tensor_slices(test)\n",
        "      test_data = test_data.batch(self.batch_size)\n",
        "\n",
        "      iterator = tf.data.Iterator.from_structure(train_data.output_types,\n",
        "                                                train_data.output_shapes)\n",
        "\n",
        "      X , label = iterator.get_next()\n",
        "      _,self.m = X.shape\n",
        "      self.X = tf.cast(X,dtype=tf.float32)\n",
        "      self.label = tf.one_hot(label,self.nclasses)\n",
        "\n",
        "      self.train_init = iterator.make_initializer(train_data)\n",
        "      self.val_init = iterator.make_initializer(val_data)\n",
        "      self.test_init = iterator.make_initializer(test_data)\n",
        "\n",
        "  def inference(self):\n",
        "    with tf.variable_scope('logreg',reuse=tf.AUTO_REUSE) as scope:\n",
        "      # Create weights and bias\n",
        "      # w is initialized to random variables with mean 0 and stddev 0.01 \n",
        "      # b is initialized to zero\n",
        "      w = tf.get_variable(name='weights',dtype=tf.float32,shape=[self.m,self.nclasses],\n",
        "                          initializer = tf.random_normal_initializer(0 , 0.01))\n",
        "      b = tf.get_variable(name='bias',shape=[self.nclasses],\n",
        "                         initializer = tf.zeros_initializer())\n",
        "\n",
        "      # build model \n",
        "      # the model that returns logits \n",
        "      self.logits = tf.matmul(self.X,w) + b\n",
        "\n",
        "  def create_loss(self):\n",
        "    with tf.name_scope('loss'):\n",
        "      # define loss function\n",
        "      entropy = tf.nn.softmax_cross_entropy_with_logits(logits = self.logits , labels = self.label)\n",
        "      self.loss = tf.reduce_mean(entropy,name='loss')\n",
        "      \n",
        "  def create_optimizer(self):\n",
        "    with tf.name_scope('optimizer'):      \n",
        "      # define training op \n",
        "      self.optimizer = tf.train.AdamOptimizer(self.lrate).minimize(self.loss)\n",
        "\n",
        "  def eval_model(self):\n",
        "    with tf.name_scope('eval'):      \n",
        "      # calculate accuracy \n",
        "      self.preds = tf.nn.softmax(self.logits)\n",
        "      self.predicted_labels = tf.argmax(self.preds,1)\n",
        "      correct_preds = tf.equal(tf.argmax(self.preds,1),tf.argmax(self.label,1))\n",
        "      self.accuracy = tf.reduce_sum(tf.cast(correct_preds,dtype=tf.float32))\n",
        "\n",
        "  def build_model(self,prep_train_data,target):\n",
        "    self.get_data(prep_train_data,target,prep_test_data)\n",
        "    self.inference()\n",
        "    self.create_loss()\n",
        "    self.create_optimizer()\n",
        "    self.eval_model()\n",
        "    \n",
        "  def train(self,n_epochs):\n",
        "    # start training loop \n",
        "    init = tf.global_variables_initializer()\n",
        "    with tf.Session() as sess:\n",
        "      sess.run(init)\n",
        "      for epoch in range(n_epochs):\n",
        "        sess.run(self.train_init)\n",
        "        total_loss = 0.0\n",
        "        n_batches = 0\n",
        "        step = 0\n",
        "        \n",
        "        try:\n",
        "          while True:\n",
        "            _,batch_loss = sess.run([self.optimizer,self.loss])\n",
        "            total_loss += batch_loss\n",
        "            n_batches += 1\n",
        "            step += 1\n",
        "            if step%100 == 0:\n",
        "              print('Step {} : Loss {}'.format(step,batch_loss))\n",
        "        \n",
        "        except tf.errors.OutOfRangeError:\n",
        "          pass\n",
        "        print('Average loss at epoch {} is {}'.format(epoch,total_loss/n_batches))\n",
        "      \n",
        "      #calculate validation set accuracy\n",
        "      sess.run(self.val_init)\n",
        "      total_acc = 0\n",
        "      try:\n",
        "        while True:\n",
        "          acc,logits = sess.run(self.accuracy)\n",
        "          total_acc += acc \n",
        "      except tf.errors.OutOfRangeError:\n",
        "        pass\n",
        "      print('Average Validation accuracy {}'.format(total_acc / 96000))\n",
        "      \n",
        "      #calculate test set predictions\n",
        "      sess.run(self.test_init)\n",
        "      predictions = []\n",
        "      try:\n",
        "        while True:\n",
        "          test_pred = sess.run(self.predicted_labels)\n",
        "          predictions.append(test_pred)\n",
        "      except tf.errors.OutOfRangeError:\n",
        "        pass\n",
        "      \n",
        "    return predictions\n",
        "       \n",
        "      \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gmFmxHjJSYFv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1489
        },
        "outputId": "4cdcb31f-84e2-4847-cb54-b4e21fbd2209"
      },
      "cell_type": "code",
      "source": [
        "#Build Model\n",
        "model = Model()\n",
        "model.build_model(prep_train_data,target)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500000, 362)\n",
            "(500000,)\n",
            "(96000, 362)\n",
            "(96000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-f4da5ad93498>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_train_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-b4bc6842ae87>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(self, prep_train_data, target)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprep_train_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_train_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprep_test_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-b4bc6842ae87>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, prep_train_data, target, prep_test_data)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m       \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m       \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    254\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \"\"\"\n\u001b[0;32m--> 256\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m   1183\u001b[0m           if sparse_tensor_lib.is_sparse(t) else ops.convert_to_tensor(\n\u001b[1;32m   1184\u001b[0m               t, name=\"component_%d\" % i)\n\u001b[0;32m-> 1185\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m       ])\n\u001b[1;32m   1187\u001b[0m       \u001b[0mflat_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1183\u001b[0m           if sparse_tensor_lib.is_sparse(t) else ops.convert_to_tensor(\n\u001b[1;32m   1184\u001b[0m               t, name=\"component_%d\" % i)\n\u001b[0;32m-> 1185\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m       ])\n\u001b[1;32m   1187\u001b[0m       \u001b[0mflat_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m   1046\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    226\u001b[0m                                          as_ref=False):\n\u001b[1;32m    227\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    205\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    206\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 207\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    208\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m   const_tensor = g.create_op(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnparray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnparray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m       raise ValueError(\n\u001b[0;32m--> 506\u001b[0;31m           \"Cannot create a tensor proto whose content is larger than 2GB.\")\n\u001b[0m\u001b[1;32m    507\u001b[0m     \u001b[0mtensor_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnparray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot create a tensor proto whose content is larger than 2GB."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "s6Kd0ajOGKis",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6981
        },
        "outputId": "98a6d46f-4bd8-450e-fefb-b3d1ff3e8c28"
      },
      "cell_type": "code",
      "source": [
        "#train model for 10 epochs\n",
        "predictions = model.train(10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 100 : Loss 0.42489755153656006\n",
            "Step 200 : Loss 0.30327871441841125\n",
            "Step 300 : Loss 0.2568695843219757\n",
            "Step 400 : Loss 0.19157129526138306\n",
            "Step 500 : Loss 0.15567736327648163\n",
            "Step 600 : Loss 0.16196492314338684\n",
            "Step 700 : Loss 0.15422973036766052\n",
            "Step 800 : Loss 0.149203360080719\n",
            "Step 900 : Loss 0.10402834415435791\n",
            "Step 1000 : Loss 0.1669762283563614\n",
            "Step 1100 : Loss 0.09747090190649033\n",
            "Step 1200 : Loss 0.14110711216926575\n",
            "Step 1300 : Loss 0.18918120861053467\n",
            "Step 1400 : Loss 0.11476323008537292\n",
            "Step 1500 : Loss 0.11519405245780945\n",
            "Step 1600 : Loss 0.18558967113494873\n",
            "Step 1700 : Loss 0.09138542413711548\n",
            "Step 1800 : Loss 0.1651363968849182\n",
            "Step 1900 : Loss 0.18966278433799744\n",
            "Step 2000 : Loss 0.10729599744081497\n",
            "Step 2100 : Loss 0.23808132112026215\n",
            "Step 2200 : Loss 0.1375671774148941\n",
            "Step 2300 : Loss 0.1386905312538147\n",
            "Step 2400 : Loss 0.18598881363868713\n",
            "Step 2500 : Loss 0.1924814134836197\n",
            "Step 2600 : Loss 0.08814670145511627\n",
            "Step 2700 : Loss 0.18665307760238647\n",
            "Step 2800 : Loss 0.08573523163795471\n",
            "Step 2900 : Loss 0.13865244388580322\n",
            "Step 3000 : Loss 0.16300152242183685\n",
            "Step 3100 : Loss 0.26267990469932556\n",
            "Step 3200 : Loss 0.1909330040216446\n",
            "Step 3300 : Loss 0.21766486763954163\n",
            "Step 3400 : Loss 0.0874413549900055\n",
            "Step 3500 : Loss 0.13943225145339966\n",
            "Step 3600 : Loss 0.10954053699970245\n",
            "Step 3700 : Loss 0.1617526412010193\n",
            "Step 3800 : Loss 0.13497400283813477\n",
            "Step 3900 : Loss 0.1865197718143463\n",
            "Average loss at epoch 0 is 0.17740242755303212\n",
            "Step 100 : Loss 0.0861281305551529\n",
            "Step 200 : Loss 0.13714565336704254\n",
            "Step 300 : Loss 0.11413794755935669\n",
            "Step 400 : Loss 0.0626889243721962\n",
            "Step 500 : Loss 0.16844967007637024\n",
            "Step 600 : Loss 0.1937638521194458\n",
            "Step 700 : Loss 0.17141425609588623\n",
            "Step 800 : Loss 0.1366105079650879\n",
            "Step 900 : Loss 0.1443529725074768\n",
            "Step 1000 : Loss 0.08904752135276794\n",
            "Step 1100 : Loss 0.12819233536720276\n",
            "Step 1200 : Loss 0.0857306644320488\n",
            "Step 1300 : Loss 0.11161862313747406\n",
            "Step 1400 : Loss 0.11272293329238892\n",
            "Step 1500 : Loss 0.13815400004386902\n",
            "Step 1600 : Loss 0.08883722126483917\n",
            "Step 1700 : Loss 0.13886573910713196\n",
            "Step 1800 : Loss 0.14783596992492676\n",
            "Step 1900 : Loss 0.24652887880802155\n",
            "Step 2000 : Loss 0.21109765768051147\n",
            "Step 2100 : Loss 0.0842164009809494\n",
            "Step 2200 : Loss 0.2030113935470581\n",
            "Step 2300 : Loss 0.09096185863018036\n",
            "Step 2400 : Loss 0.19362571835517883\n",
            "Step 2500 : Loss 0.31476470828056335\n",
            "Step 2600 : Loss 0.13460394740104675\n",
            "Step 2700 : Loss 0.1862974613904953\n",
            "Step 2800 : Loss 0.16547942161560059\n",
            "Step 2900 : Loss 0.2419116199016571\n",
            "Step 3000 : Loss 0.20567728579044342\n",
            "Step 3100 : Loss 0.21621353924274445\n",
            "Step 3200 : Loss 0.1697993278503418\n",
            "Step 3300 : Loss 0.21649909019470215\n",
            "Step 3400 : Loss 0.16197198629379272\n",
            "Step 3500 : Loss 0.08636517822742462\n",
            "Step 3600 : Loss 0.1678571254014969\n",
            "Step 3700 : Loss 0.2842627465724945\n",
            "Step 3800 : Loss 0.14254626631736755\n",
            "Step 3900 : Loss 0.11696308851242065\n",
            "Average loss at epoch 1 is 0.1538860568281388\n",
            "Step 100 : Loss 0.08771887421607971\n",
            "Step 200 : Loss 0.08169761300086975\n",
            "Step 300 : Loss 0.08381521701812744\n",
            "Step 400 : Loss 0.08603310585021973\n",
            "Step 500 : Loss 0.19772818684577942\n",
            "Step 600 : Loss 0.15705764293670654\n",
            "Step 700 : Loss 0.16496309638023376\n",
            "Step 800 : Loss 0.10950804501771927\n",
            "Step 900 : Loss 0.14104625582695007\n",
            "Step 1000 : Loss 0.21203884482383728\n",
            "Step 1100 : Loss 0.08746761828660965\n",
            "Step 1200 : Loss 0.18016773462295532\n",
            "Step 1300 : Loss 0.035452794283628464\n",
            "Step 1400 : Loss 0.24421393871307373\n",
            "Step 1500 : Loss 0.2049965113401413\n",
            "Step 1600 : Loss 0.2063218653202057\n",
            "Step 1700 : Loss 0.1140514612197876\n",
            "Step 1800 : Loss 0.16848239302635193\n",
            "Step 1900 : Loss 0.1837519407272339\n",
            "Step 2000 : Loss 0.08466962724924088\n",
            "Step 2100 : Loss 0.16176792979240417\n",
            "Step 2200 : Loss 0.08563782274723053\n",
            "Step 2300 : Loss 0.14222727715969086\n",
            "Step 2400 : Loss 0.11483253538608551\n",
            "Step 2500 : Loss 0.15491969883441925\n",
            "Step 2600 : Loss 0.12421586364507675\n",
            "Step 2700 : Loss 0.0641803964972496\n",
            "Step 2800 : Loss 0.10081984102725983\n",
            "Step 2900 : Loss 0.13895098865032196\n",
            "Step 3000 : Loss 0.18555662035942078\n",
            "Step 3100 : Loss 0.08595780283212662\n",
            "Step 3200 : Loss 0.08429902046918869\n",
            "Step 3300 : Loss 0.14262959361076355\n",
            "Step 3400 : Loss 0.08344294875860214\n",
            "Step 3500 : Loss 0.16482983529567719\n",
            "Step 3600 : Loss 0.13925820589065552\n",
            "Step 3700 : Loss 0.16140125691890717\n",
            "Step 3800 : Loss 0.13579592108726501\n",
            "Step 3900 : Loss 0.08351124823093414\n",
            "Average loss at epoch 2 is 0.1532276308358036\n",
            "Step 100 : Loss 0.1316269487142563\n",
            "Step 200 : Loss 0.1112547367811203\n",
            "Step 300 : Loss 0.20711246132850647\n",
            "Step 400 : Loss 0.16213476657867432\n",
            "Step 500 : Loss 0.16121339797973633\n",
            "Step 600 : Loss 0.1525396704673767\n",
            "Step 700 : Loss 0.09180203825235367\n",
            "Step 800 : Loss 0.1974506974220276\n",
            "Step 900 : Loss 0.16261297464370728\n",
            "Step 1000 : Loss 0.15768533945083618\n",
            "Step 1100 : Loss 0.2117495834827423\n",
            "Step 1200 : Loss 0.20286190509796143\n",
            "Step 1300 : Loss 0.09155377000570297\n",
            "Step 1400 : Loss 0.19785088300704956\n",
            "Step 1500 : Loss 0.1802523285150528\n",
            "Step 1600 : Loss 0.22870612144470215\n",
            "Step 1700 : Loss 0.1542930155992508\n",
            "Step 1800 : Loss 0.14378897845745087\n",
            "Step 1900 : Loss 0.17493532598018646\n",
            "Step 2000 : Loss 0.15732835233211517\n",
            "Step 2100 : Loss 0.057188794016838074\n",
            "Step 2200 : Loss 0.22726191580295563\n",
            "Step 2300 : Loss 0.21550309658050537\n",
            "Step 2400 : Loss 0.18368786573410034\n",
            "Step 2500 : Loss 0.14310753345489502\n",
            "Step 2600 : Loss 0.13311752676963806\n",
            "Step 2700 : Loss 0.13626787066459656\n",
            "Step 2800 : Loss 0.1331533044576645\n",
            "Step 2900 : Loss 0.14205729961395264\n",
            "Step 3000 : Loss 0.1508389115333557\n",
            "Step 3100 : Loss 0.16177114844322205\n",
            "Step 3200 : Loss 0.2175913155078888\n",
            "Step 3300 : Loss 0.08978431671857834\n",
            "Step 3400 : Loss 0.17501884698867798\n",
            "Step 3500 : Loss 0.0802331268787384\n",
            "Step 3600 : Loss 0.12093466520309448\n",
            "Step 3700 : Loss 0.14320947229862213\n",
            "Step 3800 : Loss 0.13212451338768005\n",
            "Step 3900 : Loss 0.16736260056495667\n",
            "Average loss at epoch 3 is 0.15292094365841657\n",
            "Step 100 : Loss 0.1359802782535553\n",
            "Step 200 : Loss 0.05366329476237297\n",
            "Step 300 : Loss 0.08956001698970795\n",
            "Step 400 : Loss 0.16853177547454834\n",
            "Step 500 : Loss 0.18426433205604553\n",
            "Step 600 : Loss 0.1289290189743042\n",
            "Step 700 : Loss 0.19425253570079803\n",
            "Step 800 : Loss 0.19704239070415497\n",
            "Step 900 : Loss 0.10651864856481552\n",
            "Step 1000 : Loss 0.17675909399986267\n",
            "Step 1100 : Loss 0.15808574855327606\n",
            "Step 1200 : Loss 0.2099503129720688\n",
            "Step 1300 : Loss 0.14348649978637695\n",
            "Step 1400 : Loss 0.0923905074596405\n",
            "Step 1500 : Loss 0.08861379325389862\n",
            "Step 1600 : Loss 0.1607942283153534\n",
            "Step 1700 : Loss 0.1170317679643631\n",
            "Step 1800 : Loss 0.15356145799160004\n",
            "Step 1900 : Loss 0.12715685367584229\n",
            "Step 2000 : Loss 0.09173129498958588\n",
            "Step 2100 : Loss 0.08168281614780426\n",
            "Step 2200 : Loss 0.14243516325950623\n",
            "Step 2300 : Loss 0.12334014475345612\n",
            "Step 2400 : Loss 0.16467159986495972\n",
            "Step 2500 : Loss 0.06378157436847687\n",
            "Step 2600 : Loss 0.1596236526966095\n",
            "Step 2700 : Loss 0.1371716558933258\n",
            "Step 2800 : Loss 0.16363820433616638\n",
            "Step 2900 : Loss 0.13865254819393158\n",
            "Step 3000 : Loss 0.1417757272720337\n",
            "Step 3100 : Loss 0.1565724015235901\n",
            "Step 3200 : Loss 0.19883355498313904\n",
            "Step 3300 : Loss 0.08569422364234924\n",
            "Step 3400 : Loss 0.211073100566864\n",
            "Step 3500 : Loss 0.1819981038570404\n",
            "Step 3600 : Loss 0.1349875032901764\n",
            "Step 3700 : Loss 0.10395181179046631\n",
            "Step 3800 : Loss 0.1623585820198059\n",
            "Step 3900 : Loss 0.1766940951347351\n",
            "Average loss at epoch 4 is 0.15275231545821064\n",
            "Step 100 : Loss 0.12693370878696442\n",
            "Step 200 : Loss 0.05984477698802948\n",
            "Step 300 : Loss 0.11661694198846817\n",
            "Step 400 : Loss 0.11434978246688843\n",
            "Step 500 : Loss 0.21084311604499817\n",
            "Step 600 : Loss 0.1781959980726242\n",
            "Step 700 : Loss 0.2156025618314743\n",
            "Step 800 : Loss 0.16198816895484924\n",
            "Step 900 : Loss 0.11695613712072372\n",
            "Step 1000 : Loss 0.1366584300994873\n",
            "Step 1100 : Loss 0.0846179723739624\n",
            "Step 1200 : Loss 0.057903554290533066\n",
            "Step 1300 : Loss 0.16913917660713196\n",
            "Step 1400 : Loss 0.08574892580509186\n",
            "Step 1500 : Loss 0.19262048602104187\n",
            "Step 1600 : Loss 0.1662275195121765\n",
            "Step 1700 : Loss 0.13241459429264069\n",
            "Step 1800 : Loss 0.20528388023376465\n",
            "Step 1900 : Loss 0.19058100879192352\n",
            "Step 2000 : Loss 0.11836647987365723\n",
            "Step 2100 : Loss 0.1244116798043251\n",
            "Step 2200 : Loss 0.14181163907051086\n",
            "Step 2300 : Loss 0.12630093097686768\n",
            "Step 2400 : Loss 0.11513465642929077\n",
            "Step 2500 : Loss 0.21466726064682007\n",
            "Step 2600 : Loss 0.08603891730308533\n",
            "Step 2700 : Loss 0.1939730942249298\n",
            "Step 2800 : Loss 0.14045995473861694\n",
            "Step 2900 : Loss 0.19868634641170502\n",
            "Step 3000 : Loss 0.19963577389717102\n",
            "Step 3100 : Loss 0.1050369068980217\n",
            "Step 3200 : Loss 0.243873730301857\n",
            "Step 3300 : Loss 0.2484259307384491\n",
            "Step 3400 : Loss 0.18494334816932678\n",
            "Step 3500 : Loss 0.09484079480171204\n",
            "Step 3600 : Loss 0.20056632161140442\n",
            "Step 3700 : Loss 0.2068060338497162\n",
            "Step 3800 : Loss 0.11004693806171417\n",
            "Step 3900 : Loss 0.15058603882789612\n",
            "Average loss at epoch 5 is 0.1526816461482239\n",
            "Step 100 : Loss 0.1552780419588089\n",
            "Step 200 : Loss 0.32391542196273804\n",
            "Step 300 : Loss 0.11355403065681458\n",
            "Step 400 : Loss 0.12012540549039841\n",
            "Step 500 : Loss 0.11144965142011642\n",
            "Step 600 : Loss 0.09941169619560242\n",
            "Step 700 : Loss 0.2545124888420105\n",
            "Step 800 : Loss 0.24196308851242065\n",
            "Step 900 : Loss 0.17509369552135468\n",
            "Step 1000 : Loss 0.15823408961296082\n",
            "Step 1100 : Loss 0.08219930529594421\n",
            "Step 1200 : Loss 0.21315059065818787\n",
            "Step 1300 : Loss 0.19695034623146057\n",
            "Step 1400 : Loss 0.19737455248832703\n",
            "Step 1500 : Loss 0.24070551991462708\n",
            "Step 1600 : Loss 0.12295054644346237\n",
            "Step 1700 : Loss 0.1900036334991455\n",
            "Step 1800 : Loss 0.22702258825302124\n",
            "Step 1900 : Loss 0.1378779262304306\n",
            "Step 2000 : Loss 0.180923730134964\n",
            "Step 2100 : Loss 0.104537732899189\n",
            "Step 2200 : Loss 0.18244317173957825\n",
            "Step 2300 : Loss 0.1109127625823021\n",
            "Step 2400 : Loss 0.13655437529087067\n",
            "Step 2500 : Loss 0.16717444360256195\n",
            "Step 2600 : Loss 0.11096075177192688\n",
            "Step 2700 : Loss 0.1879831850528717\n",
            "Step 2800 : Loss 0.16698282957077026\n",
            "Step 2900 : Loss 0.23608720302581787\n",
            "Step 3000 : Loss 0.138240247964859\n",
            "Step 3100 : Loss 0.20970985293388367\n",
            "Step 3200 : Loss 0.15090042352676392\n",
            "Step 3300 : Loss 0.03427176922559738\n",
            "Step 3400 : Loss 0.21059677004814148\n",
            "Step 3500 : Loss 0.11185462772846222\n",
            "Step 3600 : Loss 0.18393714725971222\n",
            "Step 3700 : Loss 0.16857561469078064\n",
            "Step 3800 : Loss 0.1406257003545761\n",
            "Step 3900 : Loss 0.18582862615585327\n",
            "Average loss at epoch 6 is 0.15256909795423923\n",
            "Step 100 : Loss 0.3072546124458313\n",
            "Step 200 : Loss 0.1338472217321396\n",
            "Step 300 : Loss 0.1743083894252777\n",
            "Step 400 : Loss 0.15349426865577698\n",
            "Step 500 : Loss 0.14901527762413025\n",
            "Step 600 : Loss 0.12276165932416916\n",
            "Step 700 : Loss 0.16597174108028412\n",
            "Step 800 : Loss 0.21151140332221985\n",
            "Step 900 : Loss 0.20413954555988312\n",
            "Step 1000 : Loss 0.1666565239429474\n",
            "Step 1100 : Loss 0.13168954849243164\n",
            "Step 1200 : Loss 0.1141211986541748\n",
            "Step 1300 : Loss 0.1609577238559723\n",
            "Step 1400 : Loss 0.18424196541309357\n",
            "Step 1500 : Loss 0.07980379462242126\n",
            "Step 1600 : Loss 0.04921858757734299\n",
            "Step 1700 : Loss 0.1576123833656311\n",
            "Step 1800 : Loss 0.12525874376296997\n",
            "Step 1900 : Loss 0.11683458834886551\n",
            "Step 2000 : Loss 0.08351454883813858\n",
            "Step 2100 : Loss 0.31481072306632996\n",
            "Step 2200 : Loss 0.16538897156715393\n",
            "Step 2300 : Loss 0.14204441010951996\n",
            "Step 2400 : Loss 0.16934965550899506\n",
            "Step 2500 : Loss 0.16583146154880524\n",
            "Step 2600 : Loss 0.13720273971557617\n",
            "Step 2700 : Loss 0.15774081647396088\n",
            "Step 2800 : Loss 0.08037471771240234\n",
            "Step 2900 : Loss 0.17182879149913788\n",
            "Step 3000 : Loss 0.08441320806741714\n",
            "Step 3100 : Loss 0.15312525629997253\n",
            "Step 3200 : Loss 0.19343528151512146\n",
            "Step 3300 : Loss 0.21491312980651855\n",
            "Step 3400 : Loss 0.18629324436187744\n",
            "Step 3500 : Loss 0.1116860955953598\n",
            "Step 3600 : Loss 0.11294492334127426\n",
            "Step 3700 : Loss 0.1897040605545044\n",
            "Step 3800 : Loss 0.17336660623550415\n",
            "Step 3900 : Loss 0.10913390666246414\n",
            "Average loss at epoch 7 is 0.1525621265192028\n",
            "Step 100 : Loss 0.1869162619113922\n",
            "Step 200 : Loss 0.059052545577287674\n",
            "Step 300 : Loss 0.13354191184043884\n",
            "Step 400 : Loss 0.17874829471111298\n",
            "Step 500 : Loss 0.20484116673469543\n",
            "Step 600 : Loss 0.13172858953475952\n",
            "Step 700 : Loss 0.1028309017419815\n",
            "Step 800 : Loss 0.16460537910461426\n",
            "Step 900 : Loss 0.1820455640554428\n",
            "Step 1000 : Loss 0.24132105708122253\n",
            "Step 1100 : Loss 0.19345945119857788\n",
            "Step 1200 : Loss 0.15344125032424927\n",
            "Step 1300 : Loss 0.15564866364002228\n",
            "Step 1400 : Loss 0.1099172830581665\n",
            "Step 1500 : Loss 0.15481773018836975\n",
            "Step 1600 : Loss 0.17114505171775818\n",
            "Step 1700 : Loss 0.18993401527404785\n",
            "Step 1800 : Loss 0.17167645692825317\n",
            "Step 1900 : Loss 0.1330014169216156\n",
            "Step 2000 : Loss 0.23913802206516266\n",
            "Step 2100 : Loss 0.10954584181308746\n",
            "Step 2200 : Loss 0.2076512575149536\n",
            "Step 2300 : Loss 0.28364503383636475\n",
            "Step 2400 : Loss 0.10372917354106903\n",
            "Step 2500 : Loss 0.12409046292304993\n",
            "Step 2600 : Loss 0.15448659658432007\n",
            "Step 2700 : Loss 0.20088818669319153\n",
            "Step 2800 : Loss 0.19636479020118713\n",
            "Step 2900 : Loss 0.1408207267522812\n",
            "Step 3000 : Loss 0.1792394518852234\n",
            "Step 3100 : Loss 0.24608971178531647\n",
            "Step 3200 : Loss 0.03724783658981323\n",
            "Step 3300 : Loss 0.037227123975753784\n",
            "Step 3400 : Loss 0.08996061980724335\n",
            "Step 3500 : Loss 0.20329943299293518\n",
            "Step 3600 : Loss 0.09307702630758286\n",
            "Step 3700 : Loss 0.10945723950862885\n",
            "Step 3800 : Loss 0.2074415534734726\n",
            "Step 3900 : Loss 0.2245827168226242\n",
            "Average loss at epoch 8 is 0.15249804103766557\n",
            "Step 100 : Loss 0.10177714377641678\n",
            "Step 200 : Loss 0.14212453365325928\n",
            "Step 300 : Loss 0.11508230865001678\n",
            "Step 400 : Loss 0.18123844265937805\n",
            "Step 500 : Loss 0.16739444434642792\n",
            "Step 600 : Loss 0.15928326547145844\n",
            "Step 700 : Loss 0.06238148361444473\n",
            "Step 800 : Loss 0.16482260823249817\n",
            "Step 900 : Loss 0.1390203833580017\n",
            "Step 1000 : Loss 0.15863147377967834\n",
            "Step 1100 : Loss 0.0673123300075531\n",
            "Step 1200 : Loss 0.13495323061943054\n",
            "Step 1300 : Loss 0.2634800970554352\n",
            "Step 1400 : Loss 0.10093015432357788\n",
            "Step 1500 : Loss 0.2357243299484253\n",
            "Step 1600 : Loss 0.116923026740551\n",
            "Step 1700 : Loss 0.18177485466003418\n",
            "Step 1800 : Loss 0.18372678756713867\n",
            "Step 1900 : Loss 0.1862485408782959\n",
            "Step 2000 : Loss 0.19345134496688843\n",
            "Step 2100 : Loss 0.12256309390068054\n",
            "Step 2200 : Loss 0.06067415699362755\n",
            "Step 2300 : Loss 0.11449148505926132\n",
            "Step 2400 : Loss 0.13778077065944672\n",
            "Step 2500 : Loss 0.11165142059326172\n",
            "Step 2600 : Loss 0.12946683168411255\n",
            "Step 2700 : Loss 0.11621889472007751\n",
            "Step 2800 : Loss 0.13048794865608215\n",
            "Step 2900 : Loss 0.25952112674713135\n",
            "Step 3000 : Loss 0.10968910157680511\n",
            "Step 3100 : Loss 0.17681723833084106\n",
            "Step 3200 : Loss 0.05656567960977554\n",
            "Step 3300 : Loss 0.10829423367977142\n",
            "Step 3400 : Loss 0.2521204352378845\n",
            "Step 3500 : Loss 0.24336495995521545\n",
            "Step 3600 : Loss 0.18252788484096527\n",
            "Step 3700 : Loss 0.20930831134319305\n",
            "Step 3800 : Loss 0.17047491669654846\n",
            "Step 3900 : Loss 0.10736645758152008\n",
            "Average loss at epoch 9 is 0.15246547797767745\n",
            "Average accuracy 0.9637291666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rcbl77wKQZu9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5a1931f-a6c2-4c5f-e76c-20b72af17cfc"
      },
      "cell_type": "code",
      "source": [
        "predictions = [logits for sub_list in pred_logits for logits in sub_list]\n",
        "print(len(pred_logits))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uAmmoDDpbFZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6e8a816-f6ad-4133-ef1d-34f232ddd458"
      },
      "cell_type": "code",
      "source": [
        "pred_logits[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.95937926, 0.04062074], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "TlF9Dgq7ZrIi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}